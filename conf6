ğŸ§­ 1. Overview

Objective

This document outlines an AI-assisted API Automation Framework built using Playwright and Cucumber.js, which automates API endpoint validation directly from Swagger definitions.

Purpose

To create a configuration-driven, schema-validated, and visually reportable API automation suite that:

Runs against Swagger/OpenAPI-defined endpoints

Validates API contract compliance (schema validation)

Categorizes failures (Critical, Validation Gaps, Schema Violations)

Generates multiple report formats (Cucumber HTML/JSON, Allure dashboard, TEST_SUMMARY.md)

Requires zero manual intervention after initial .env configuration

Key Highlights

â— Config-driven approach: Read API specification and authentication from .env file. 

â— Auto-generates Playwright + Cucumber test suites from Swagger/OpenAPI (JSON or URL). 

â— Schema validation: Validates response structure using Ajv (required fields + data types). 

â— Allure reporting: Interactive HTML dashboards with test statistics and trends. 

â— Automatic retry logic: 3 attempts per scenario for transient failures. 

â— Flexible authentication: Supports Basic Auth, Bearer Token, or none. 

â— Seamlessly integrates with GitHub Copilot.

Technical Stack

ğŸ§© Playwright â€“ APIRequestContext for HTTP calls and response handling

ğŸ§  Cucumber.js v10+ â€“ BDD test framework with retry configuration

âœ… Chai v5+ â€“ Assertion library for response validation

ğŸ”’ Ajv v8+ â€“ JSON Schema validation for API contract compliance

ğŸ“Š Allure â€“ Primary reporting tool with interactive dashboards

ğŸ¤– GitHub Copilot â€“ AI-powered test generation from .copilot-instructions

ğŸ” dotenv â€“ Environment variable management

âš™ï¸ 2. Prerequisites

â— Active GitHub Copilot Business License 

â— Node.js v18+ and npm 

â— Playwright v1.45+ (APIRequestContext support) 

â— Swagger/OpenAPI specification (JSON file or URL)

â— .env file - Environment variables used during test execution

ğŸ’» Supported IDEs

The framework is compatible with both:

IDE

Status

Notes

VS Code       

âœ… Recommended 

Seamless Copilot & GHCP integration        

ğŸ§© 3. Architecture Diagram

Key Features

Configuration-Driven: All settings in .env (no hardcoded values)

Schema Validation: Validates response structure against API specification

Automatic Retry: Cucumber retries failed scenarios 3 times

Failure Categorization: Critical, Validation Gaps, Schema Violations, Not Applicable

Multiple Reports: Cucumber, Allure, and markdown summaries

ğŸš€ 4. Setup & Configuration

Step 1: Configure .env File 

Create a .env file at the project root and add the required environment variables (INPUT_TYPE, INPUT_PATH, AUTH_TYPE)

Step 2: Create .copilot-instructions file

Create a .copilot-instructions file in the project root and add the prompts that instruct GitHub copilot to generate API tests.

Step 3: Provide the â€˜User Promptâ€™ to GitHub Copilot in the GHCP Chat. 

ğŸ§ª 5. Test Coverage

For Each Endpoint Operation:

1. Positive Scenarios (200/201/204)

Validates successful operations per Swagger definitions

Schema validation performed on responses:

GET (200): ALWAYS validate response schema

POST/PUT (200/201): Validate IF response returns an object

If test fails â†’ indicates API bug (not test bug)

2. Negative Scenarios

HTTP Method

Tested Negative Codes

GET

401, 404, 500

POST

400, 401, 404, 500

PUT

400, 404, 500

DELETE

400, 404, 500

Note: Negative tests may fail if:

API lacks input validation (returns 200 instead of 400) â†’ Validation Gap

API returns wrong error code (returns 500 instead of 400) â†’ Wrong Error Code

These are documented in TEST_SUMMARY.md as expected failures.

ğŸ”„ 6. Retry & Failure Handling

Automatic Retry Logic

Cucumber configuration: retry: 3 (3 attempts per scenario)

Purpose: Handle transient environment issues (network glitches, temporary service issues)

Behavior:

Test fails â†’ automatically retries up to 3 times

Passes on retry â†’ transient issue (test passes)

Fails all 3 retries â†’ genuine API issue (marked as FAILED)

Failure Categorization

All failures are documented in TEST_SUMMARY.md:

1. Positive Scenario Failures (CRITICAL)

Swagger-defined success responses that fail

Example: POST expects 200 but returns 500

Action: These indicate API bugs

2. Negative Scenario Failures - Validation Gaps

API returns 200 instead of 400 (missing input validation)

Documented in "Not Applicable Test Cases"

Reason: API lacks input validation

3. Negative Scenario Failures - Wrong Error Code

API returns 500 instead of 400/404

Documented in "Failed Test Cases â†’ Negative Scenarios"

Reason: API has poor error handling

4. Schema Validation Failures (CRITICAL)

Response structure doesn't match API specification

Examples: Missing required fields, wrong data types, unexpected fields

Action: API contract violation - requires immediate attention

ğŸ“Š 7. Reporting

Three Report Types Generated:

1. Cucumber HTML/JSON Reports

Location: cucumber-report.html, cucumber-report.json

Basic test execution summary with step-level details

2. Allure Report (Primary)

Generate the report using the test run (Allure results get stored in allure-results/folder).     

To open the Allure dashboard, run â€˜npm run allure:openâ€™.

Interactive dashboard with:

Test statistics and trends

Categorized failures

Step-level logs and stack traces

Drill-down capabilities

Open with: npm run allure:open

3. TEST_SUMMARY.md

Comprehensive markdown summary with:

Test Results (Total, Passed, Failed, Success Rate)

Test Coverage by Endpoint (âœ…/âŒ/âš ï¸)

Failed Test Cases (categorized by type)

Not Applicable Test Cases (validation gaps)

API Issues Requiring Attention (Critical vs Behavior Issues)

Next Steps (prioritized action items)

ğŸ§ª 8. Sample Test Case

Feature: Order Management API

  @order @positive
  Scenario: Successfully place a new order
    Given I have a valid order payload
    When I send a POST request to "/store/order"
    Then the response status code should be 200
    And the response should match the order schema
    And the response should contain field "id"

  @order @negative
  Scenario: Place order with missing required fields
    Given I have an order payload with missing required field "productId"
    When I send a POST request to "/store/order"
    Then the response status code should be 400

Note:

Each test is self-contained with automatic retry (3 attempts)

Schema validation is performed on successful responses

Failures are categorized and documented in TEST_SUMMARY.md

ğŸ” 9. Key Observations

Configuration-Driven Approach

All configuration centralized in .env file

No hardcoded values in test code

Easy to switch between environments or API specifications

Parallel Execution Support

The framework supports full parallel execution using cucumber.js (--parallel), with each scenario running in its own isolated manner.

Ensures thread-safe execution by creating a separate playwright context per worker, enabling high-scale API test runs.

Schema Validation

Validates API contract compliance using Ajv

Catches response structure issues early

Documented as CRITICAL failures (API contract violations)

Authentication Flexibility

Supports multiple auth types: basic, bearer, none

Configured via AUTH_TYPE in .env

No code changes needed to switch auth methods

Test Philosophy

Tests NEVER modified to match API behavior

Tests reflect expected behavior per specification

Failures indicate API issues, not test issues

Pass rate may be < 100% due to API bugs (this is expected)

ğŸ 10. Conclusion

This framework demonstrates how Playwright + Cucumber + Ajv + Allure + GitHub Copilot can automate comprehensive API testing using Swagger/OpenAPI specifications with:

âœ… Zero manual intervention after .env configuration
âœ… Schema validation for API contract compliance
âœ… Flexible authentication (basic/bearer/none)
âœ… Automatic retry logic (3 attempts per scenario)
âœ… Visual reporting with Allure dashboards
âœ… Failure categorization (Critical, Validation Gaps, Schema Violations)
âœ… AI-assisted test generation via GitHub Copilot

The framework ensures reliable, repeatable regression testing that adapts dynamically to API changes while maintaining strict validation of API contracts and behavior.

Sample Executions

Product Team

Prompt Used

Input URL (Swagger/json)

Output (Regression Test Files)

Final Execution Report

O9



https://pigw-mpcon-ca.marksandspencer.app/swagger-ui.html















